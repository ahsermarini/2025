# Install all packages for the project needed

install.packages("terra")
install.packages("tidyterra")
install.packages("dplyr")
install.packages("geodata")
install.packages("predicts")
install.packages("raster")
install.packages("ggplot2")
install.packages("maps")

# Accessing all required packages 

library(terra)         # Tools for spatial data manipulation (raster/vector)
library(tidyterra)     # Integrates 'terra' with 'tidyverse' for tidy data workflows
library(dplyr)         # Tidyverse package for data manipulation
library(geodata)       # Access and download geospatial/climate data
library(predicts)      # Spatial predictive modeling, e.g., species distribution
library(raster)        # Spatial raster data analysis and modeling
library(ggplot2)       # Data visualization with customizable plots
library(maps)          # World map data for geographic visualization

# Setting up the working directory 
setwd("C:/Users/serma/OneDrive - Alma Mater Studiorum Università di Bologna/Desktop/Invasive_USA")

# loading the dataset from USGS Nonindigenous Aquatic Species
usgs_data <- read.csv("C:/Users/serma/OneDrive - Alma Mater Studiorum Università di Bologna/Desktop/Invasive_USA/BP.csv")

# --- Cleaning data and preparing new CSV  ---

# View the structure of the dataset
str(usgs_data)

# view first few rows of the dataset
head(usgs_data)

# Keeping relevant columns: scientificName, state, longitude, latitude, and year
columns_to_keep <- c("Scientific.Name", "State", "Latitude", "Longitude", "Year")
columns_to_keep <- columns_to_keep[columns_to_keep %in% colnames(usgs_data)] 
filtered_data <- usgs_data[, columns_to_keep]

# Check how many non-numerical or missing values there are for longitude and latitude
non_numeric_long <- sum(is.na(as.numeric(filtered_data$Longitude)))
non_numeric_lat <- sum(is.na(as.numeric(filtered_data$Latitude)))
non_numeric_year <- sum(is.na(as.numeric(filtered_data$Year)))

# Rename name without period
filtered_data <- filtered_data %>% rename("Scientific Name" = Scientific.Name)

# Filter out observations from Ohio (OH)
filtered_data <- filtered_data %>% filter(State != "OH")

# Write cleaned data to CSV
write.csv(filtered_data, file="python_bivittatus_cleaned.csv", row.names = FALSE)

# --- Data from WorldClima ---

# Download present bioclimatic data
bioclim_present <- worldclim_global(var = "bio", res = 5, path = "data/")

# Download future bioclimatic data
bioclim_future <- cmip6_world(model = "MPI-ESM1-2-HR", ssp = "585", time = "2061-2080", var = "bioc", res = 5, path = "data/")

## Downloading present & future bioclimatic variable data 
bioclim_data <- worldclim_global(var = "bio",
                                 res = 5,
                                 path = "data/")

# --- Plotting current occurrences on map ---

# Define geographic extent
max_lat <- ceiling(max(filtered_data$Latitude))
min_lat <- floor(min(filtered_data$Latitude))
max_lon <- ceiling(max(filtered_data$Longitude))
min_lon <- floor(min(filtered_data$Longitude))
extent_bounds <- ext(c(min_lon, max_lon, min_lat, max_lat))

# Store boundaries in a single extent object
geographic_extent <- ext(x = c(min_lon, max_lon, min_lat, max_lat))

# Downloading data with geodata's world function to use for our base map
world_map <- world(resolution = 3,
                   path = "data/")

# Use the boundaries of the mainland USA for the extent
southeast_extent <- ext(c(-88.0, -80.0, 24.396308, 36.5))

# Cropping the map to the mainland USA extent
my_map <- crop(x = world_map, y = southeast_extent)

# Plotting the base map for BP
plot(my_map,
     axes = TRUE, 
     col = "grey95",
     main = "Occurrence of Python Bivittatus Present")

# Adding the points for individual observations present
points(x = filtered_data$Longitude, 
       y = filtered_data$Latitude, 
       col = "olivedrab", 
       pch = 20, 
       cex = 0.80)

# Make an extent that is 25% larger
sample_extent <- geographic_extent * 1.25

# Crop for Present BioClima map
bioclim_present <- crop(x = bioclim_data, y = southeast_extent)

# Print predicted values 
plot(bioclim_present[[1]], main = "Occurrence of Python Bivittatus Current Climate Prediciton")

# --- Preparing for RCP 8.5 for Python Biovittatus Model ---

# Setting the seed for the random-number generator to ensure results are similar
set.seed(123)

# Randomly sample points for psudo-absence 
background <- spatSample(x = bioclim_data,
                         size = 1000,
                         values = FALSE, # don't need values
                         na.rm = TRUE,   # don't sample from ocean
                         xy = TRUE)      # just need coordinates

# Define the geographic extent for the contiguous USA (excluding Alaska and Hawaii)
contiguous_usa_extent <- ext(c(-125.0, -66.9, 24.396308, 49.384358))  # Mainland USA boundaries

# Crop the world map to only the contiguous USA
contiguous_usa_map <- crop(x = world_map, y = contiguous_usa_extent)

# Plot the base map for Python Bivittatus (Mainland USA Only)
plot(contiguous_usa_map,
     axes = TRUE, 
     col = "grey95",
     main = "Occurrence of Python Bivittatus (Mainland USA Only)")

# Adding background points
points(background,
       col = "grey30",
       pch = 1,
       cex = 0.75)

# Adding the points for individual observations
points(x = filtered_data$Longitude, 
       y = filtered_data$Latitude, 
       col = "olivedrab", 
       pch = 20, 
       cex = 0.80)

# --- Creating Data Frame for Psudo-Absence and Occurrences Combo ---

# Pulling out coordinate columns for LONG and LAT
presence1 <- filtered_data[, c("Longitude", "Latitude")]

# Add column indicating presence
presence1$pa1 <- 1

# Convert background data to a data frame
absence1 <- as.data.frame(background)

# Update column names so they match presence points
colnames(absence1) <- c("Longitude", "Latitude")

# Add column indicating absence
absence1$pa1 <- 0

# Joining data into single data frame
all_points1 <- rbind(presence1, absence1)

head(all_points1)

# Extracting climate data for all those points
bioclim_extract1 <- extract(x = bioclim_data,
                            y = all_points1[, c("Longitude", "Latitude")],
                            ID = FALSE) 

# Adding the point and climate datasets together
points_climate1 <- cbind(all_points1, bioclim_extract1)

# Identifying columns that are latitude & longitude
drop_cols1 <- which(colnames(points_climate1) %in% c("Longitude", "Latitude"))

# Removing the geographic coordinates from the data frame
points_climate1 <- points_climate1[, -drop_cols1]

# --- Training & Testing Data Set for RCP 8.5 ---

# Creating vector indicating fold to separate training and testing data
fold1 <- folds(x = points_climate1,
               k = 5,
               by = points_climate1$pa1)

# Separating data into training and testing sets
testing1 <- points_climate1[fold1 == 1, ]
training1 <- points_climate1[fold1 != 1, ]

                             
                             
                             
                             
# --- Model Builiding for RCP 8.5 ---

# Building a model using training data
glm_model1 <- glm(pa1~., data = training1, family = binomial())

# Getting predicted values from the model
glm_predict1 <- predict(bioclim_data, glm_model1, type = "response")

# Plot the prediction but limit the extent to mainland USA
plot(glm_predict1,main = "Occurrence of Python Bivittatus Current Climate RCP 8.5", xlim = c(-95, -78), ylim = c(24, 36))  



